{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/annabroido/Dropbox/Research/LRTAnalysis/SFAnalysis/analysis/')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importfiles as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_pickle('/Users/annabroido/Dropbox/Research/LRTAnalysis/SFAnalysis/local/newanalysis.p')\n",
    "df = df.query(\"Domain != 'Economic'\")\n",
    "df = df.query(\"alpha != ''\")\n",
    "# NOTE THAT 'IN' MEAN IN TO THE ALT DISTRIBUTION, WHCIH IS NOT WHAT MATHEMATICA DOES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(927,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df2.fp_gml.values).shape\n",
    "#np.sum([gml in cat.fp_gml.values for gml in np.unique(df.fp_gml)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Subdomain</th>\n",
       "      <th>num_edges</th>\n",
       "      <th>Graph_order</th>\n",
       "      <th>Weighted</th>\n",
       "      <th>Directed</th>\n",
       "      <th>Bipartite</th>\n",
       "      <th>Multigraph</th>\n",
       "      <th>Multiplex</th>\n",
       "      <th>Component</th>\n",
       "      <th>...</th>\n",
       "      <th>n</th>\n",
       "      <th>alpha</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ntail</th>\n",
       "      <th>Lpl</th>\n",
       "      <th>ppl</th>\n",
       "      <th>dexp</th>\n",
       "      <th>dln</th>\n",
       "      <th>dstrexp</th>\n",
       "      <th>dplwc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Domain, Subdomain, num_edges, Graph_order, Weighted, Directed, Bipartite, Multigraph, Multiplex, Component, fp_gml, n, alpha, xmin, ntail, Lpl, ppl, dexp, dln, dstrexp, dplwc]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.fp_gml == '/Volumes/Durodon/gmls/Technological/Communication/n4/Route_Views_AS_graphs_1997-1998_as19971210_Technological_Communication_n4.gml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df2 = pd.read_pickle('/Users/annabroido/Dropbox/Research/LRTAnalysis/SFAnalysis/analysis/analysis.p')\n",
    "# cat = pd.read_pickle('newgmlcatalog.p')\n",
    "# cat2 = pd.read_pickle('/Users/annabroido/Dropbox/Research/LRTAnalysis/SFAnalysis/analysis/gmlcatalog.p')\n",
    "len(cat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getcount(decision, direction, df=df):\n",
    "    directiondir = {'in':'-1', 'out':'1', 'unk':'0', 'fail':'2'}\n",
    "    query = '%s == %s' %(decision, directiondir[direction])\n",
    "    num = len(np.asarray(df.query(query)[decision], dtype=int))\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[767, 1061, 995, 1321]\n",
      "[2050, 399, 1822, 0]\n",
      "[528, 2100, 743, 2340]\n",
      "[316, 101, 101]\n"
     ]
    }
   ],
   "source": [
    "# plot some stuff\n",
    "expin = getcount('dexp', 'in')\n",
    "expout = getcount('dexp', 'out')\n",
    "expunk = getcount('dexp', 'unk')\n",
    "expfail = getcount('dexp', 'fail')\n",
    "lnin = getcount('dln', 'in')\n",
    "lnout = getcount('dln', 'out')\n",
    "lnunk = getcount('dln', 'unk')\n",
    "lnfail = getcount('dln', 'fail')\n",
    "strexpin = getcount('dstrexp', 'in')\n",
    "strexpout = getcount('dstrexp', 'out')\n",
    "strexpunk = getcount('dstrexp', 'unk')\n",
    "strexpfail = getcount('dstrexp', 'fail')\n",
    "plwcin = getcount('dplwc', 'in')\n",
    "plwcout = getcount('dplwc', 'out')\n",
    "plwcunk = getcount('dplwc', 'unk')\n",
    "# order = \"LN\", \"Exp\", \"Str Exp\", \"PLwC\"\n",
    "incounts = [expin, lnin, strexpin, plwcin]\n",
    "outcounts = [expout, lnout, strexpout, plwcout]\n",
    "unkcounts = [expunk, lnunk, strexpunk, plwcunk]\n",
    "print incounts\n",
    "print outcounts\n",
    "print unkcounts\n",
    "print [expfail, lnfail, strexpfail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_datasets = np.unique(df.fp_gml)\n",
    "decisions = ['dexp','dln', 'dstrexp', 'dplwc']\n",
    "allcounts = np.zeros((3,4))\n",
    "# each column of counts (stack in, on, and unk) adds up to len(rows) unless some fail\n",
    "for i, dataset in enumerate(unique_datasets):\n",
    "    query = \"fp_gml == '%s'\" %dataset\n",
    "    rows = df.query(query)\n",
    "    counts = np.zeros((3,4)) # rows are in, out, and unk \n",
    "    for i, decision in enumerate(decisions):\n",
    "        counts[0,i] = getcount(decision, 'out', rows)\n",
    "        counts[1,i] = getcount(decision, 'unk', rows)\n",
    "        counts[2,i] = getcount(decision, 'in', rows)\n",
    "        counts[1,i]+= getcount(decision,'fail',rows)\n",
    "    counts=counts/len(rows) # normalize each dataset\n",
    "    allcounts += counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unique_datasets = np.unique(df.fp_gml)\n",
    "# decisions = ['dexp','dln', 'dstrexp', 'dplwc']\n",
    "# allcounts = np.zeros((3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrtproportions = 100*allcounts/len(unique_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M_PL</th>\n",
       "      <th>Inconclusive</th>\n",
       "      <th>M_Alt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Exponential</th>\n",
       "      <td>55.6829</td>\n",
       "      <td>23.0009</td>\n",
       "      <td>21.2984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log-normal</th>\n",
       "      <td>7.65119</td>\n",
       "      <td>66.768</td>\n",
       "      <td>25.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weibull</th>\n",
       "      <td>45.7112</td>\n",
       "      <td>29.5779</td>\n",
       "      <td>24.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLwC</th>\n",
       "      <td>0</td>\n",
       "      <td>68.9467</td>\n",
       "      <td>31.0355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                M_PL Inconclusive    M_Alt\n",
       "Exponential  55.6829      23.0009  21.2984\n",
       "Log-normal   7.65119       66.768   25.563\n",
       "Weibull      45.7112      29.5779  24.6931\n",
       "PLwC               0      68.9467  31.0355"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countdf = pd.DataFrame(index=['Exponential', 'Log-normal', 'Weibull', 'PLwC'], columns=['M_PL', 'Inconclusive', 'M_Alt'])\n",
    "countdf.loc['Exponential'] = lrtproportions[:,0]\n",
    "countdf.loc['Log-normal'] = lrtproportions[:,1]\n",
    "countdf.loc['Weibull'] = lrtproportions[:,2]\n",
    "countdf.loc['PLwC'] = lrtproportions[:,3]\n",
    "countdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# doms = np.unique(df.Domain)\n",
    "# # number of graphs and mean alpha value in each domain\n",
    "# counts = np.zeros_like(doms)\n",
    "# means = np.zeros_like(doms)\n",
    "# counts_plaus = np.zeros_like(doms)\n",
    "# means_plaus = np.zeros_like(doms)\n",
    "# counts_plaustail = np.zeros_like(doms)\n",
    "# means_plaustail = np.zeros_like(doms)\n",
    "# for i,dom in enumerate(doms):\n",
    "#     query = \"Domain == '%s'\" %dom\n",
    "#     subdf = df.query(query)\n",
    "#     counts[i] = len(subdf)\n",
    "#     means[i] = format(np.mean(subdf.alpha), '.2f')\n",
    "#     subdf_plaus = subdf.query(\"ppl>0.1\")\n",
    "#     counts_plaus[i] = len(subdf_plaus)\n",
    "#     means_plaus[i] = format(np.mean(subdf_plaus.alpha), '.2f')\n",
    "#     subdf_plaustail = subdf_plaus.query(\"ntail>=50\")\n",
    "#     counts_plaustail[i] = len(subdf_plaustail)\n",
    "#     means_plaustail[i] = format(np.mean(subdf_plaustail.alpha), '.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print doms\n",
    "# print counts_plaustail\n",
    "# print means_plaustail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_strong_noplwc(rows):\n",
    "    ''' neither have plwc, the weaker one has no range on alpha'''\n",
    "    A1 = False # strongnoplwc\n",
    "    A2 = False # no plwc or range\n",
    "    n = len(rows)\n",
    "    np = 0 #noplwc\n",
    "    npnr = 0 #noplwcnorange\n",
    "    for ind, row in rows.iterrows():\n",
    "        if row.ppl>0.1 and row.ntail >= 50 and row.dexp >-1 and row.dln>-1  and row.dstrexp >-1:\n",
    "            npnr += 1\n",
    "            if row.alpha < 3 and row.alpha > 2:\n",
    "                np += 1\n",
    "    if np >= n/2.:\n",
    "        A1 = True\n",
    "    if npnr>= n/2.:\n",
    "        A2 = True\n",
    "    return (A1, A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_datasets = np.unique(df.fp_gml)\n",
    "althyps = pd.DataFrame(columns = [\"No_PLwC\", \"No_PLwC_No_Range\"], index=unique_datasets )\n",
    "for i, dataset in enumerate(unique_datasets):\n",
    "    query = \"fp_gml == '%s'\" %dataset\n",
    "    rows = df.query(query)\n",
    "    [A1, A2] = test_strong_noplwc(rows)\n",
    "    althyps.loc[dataset]['No_PLwC'] = A1\n",
    "    althyps.loc[dataset]['No_PLwC_No_Range'] = A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def test_strong(rows):\n",
    "#     S1 = False # strongest\n",
    "#     S2 = False # strong\n",
    "#     SA = False\n",
    "#     n = len(rows)\n",
    "#     strong = 0\n",
    "#     strong_alone = 0\n",
    "#     for ind, row in rows.iterrows():\n",
    "#         if row.ppl>0.1 and row.ntail >= 50 and row.alpha < 3 and row.alpha > 2:\n",
    "#             strong_alone += 1\n",
    "#             if row.dexp >-1 and row.dln>-1  and row.dstrexp >-1  and row.dplwc >-1:\n",
    "#                 strong += 1\n",
    "#     if strong_alone >= 9.*n/10:\n",
    "#         SA = True\n",
    "#     if strong >= n/2.:\n",
    "#         S2 = True\n",
    "#     if SA == True and strong >= 95.*n/100:\n",
    "#         S1 = True\n",
    "#     return (S1, S2)\n",
    "\n",
    "def test_strongest_noplwc(rows):\n",
    "    ''' neither have plwc, the weaker one has no range on alpha'''\n",
    "    A1 = False # noplwcstrongest\n",
    "    A2 = False # no plwc or range strongest\n",
    "    n = len(rows)\n",
    "    nps = 0 #strongestnoplwc\n",
    "    npnrs = 0 #noplwcnorange\n",
    "    alts = 0\n",
    "    for ind, row in rows.iterrows():\n",
    "        if row.ppl>0.1 and row.ntail >= 50:\n",
    "            npnrs += 1\n",
    "            if row.dexp >-1 and row.dln>-1  and row.dstrexp >-1:\n",
    "                alts+= 1\n",
    "            if row.alpha < 3 and row.alpha > 2:\n",
    "                nps += 1\n",
    "    if alts >= 95.*n/100. and nps >= 90.*n/100.:\n",
    "        A1 = True\n",
    "    if alts >= 95.*n/100. and npnrs >= 95.*n/100.:\n",
    "        A2 = True\n",
    "    return (A1, A2)\n",
    "\n",
    "def test_weak_noplwc(rows):\n",
    "    W = False \n",
    "    West = False \n",
    "    SW = False\n",
    "    n = len(rows)\n",
    "    weak = 0\n",
    "    weakest = 0\n",
    "    sweak = 0\n",
    "    for ind, row in rows.iterrows():\n",
    "        if row.ppl>0.1:\n",
    "            weakest += 1\n",
    "            if row.ntail>=50:\n",
    "                weak += 1\n",
    "        if row.dexp >-1 and row.dln>-1  and row.dstrexp >-1:\n",
    "            sweak += 1\n",
    "    if weak >= n/2.:\n",
    "        W = True\n",
    "    if weakest >= n/2.:\n",
    "        West = True\n",
    "    if sweak >= n/2.:\n",
    "        SW = True\n",
    "    return (W, West, SW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_strong_any(rows):\n",
    "    ''' just need a minimum of one dataset'''\n",
    "    S = False # strongest/strong\n",
    "    n = len(rows)\n",
    "    strong_alone = 0 #noplwc\n",
    "    strong = 0\n",
    "    for ind, row in rows.iterrows():\n",
    "        if row.ppl>0.1 and row.ntail >= 50 and row.alpha <3 and row.alpha > 2:\n",
    "            if row.dexp >-1 and row.dln>-1  and row.dstrexp >-1 and row.dplwc >-1:\n",
    "                strong += 1\n",
    "    if strong>= 1:\n",
    "        S = True\n",
    "    return (S)\n",
    "\n",
    "def test_weak_any(rows):\n",
    "    ''' just need a minimum of one dataset'''\n",
    "    W = False \n",
    "    West = False \n",
    "    SW = False\n",
    "    n = len(rows)\n",
    "    weak = 0\n",
    "    weakest = 0\n",
    "    sweak = 0\n",
    "    for ind, row in rows.iterrows():\n",
    "        if row.ppl>0.1:\n",
    "            weakest += 1\n",
    "            if row.ntail>=50:\n",
    "                weak += 1\n",
    "        if row.dexp >-1 and row.dln>-1  and row.dstrexp >-1  and row.dplwc >-1:\n",
    "            sweak += 1\n",
    "    if weak >= 1:\n",
    "        W = True\n",
    "    if weakest >= 1:\n",
    "        West = True\n",
    "    if sweak >= 1:\n",
    "        SW = True\n",
    "    return (W, West, SW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_strong_any_noplwc(rows):\n",
    "    ''' just need a minimum of one dataset, no plwc'''\n",
    "    S = False # strongest/strong\n",
    "    n = len(rows)\n",
    "    strong_alone = 0 #noplwc\n",
    "    strong = 0\n",
    "    for ind, row in rows.iterrows():\n",
    "        if row.ppl>0.1 and row.ntail >= 50 and row.alpha <3 and row.alpha > 2:\n",
    "            if row.dexp >-1 and row.dln>-1  and row.dstrexp >-1:\n",
    "                strong += 1\n",
    "    if strong>= 1:\n",
    "        S = True\n",
    "    return (S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_strong_any_nobounds(rows):\n",
    "    ''' just need a minimum of one dataset, no plwc, nobounds'''\n",
    "    S = False # strongest/strong\n",
    "    n = len(rows)\n",
    "    strong_alone = 0 #noplwc\n",
    "    strong = 0\n",
    "    for ind, row in rows.iterrows():\n",
    "        if row.ppl>0.1 and row.ntail >= 50:\n",
    "            if row.dexp >-1 and row.dln>-1  and row.dstrexp >-1:\n",
    "                strong += 1\n",
    "    if strong>= 1:\n",
    "        S = True\n",
    "    return (S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_strong(rows):\n",
    "    S1 = False # strongest\n",
    "    S2 = False # strong\n",
    "    SA = False\n",
    "    n = len(rows)\n",
    "    strong = 0\n",
    "    strong_alone = 0\n",
    "    for ind, row in rows.iterrows():\n",
    "        if row.ppl>0.1 and row.ntail >= 50 and row.alpha < 3 and row.alpha > 2:\n",
    "            strong_alone += 1\n",
    "            if row.dexp >-1 and row.dln>-1  and row.dstrexp >-1  and row.dplwc >-1:\n",
    "                strong += 1\n",
    "    if strong_alone >= 9.*n/10:\n",
    "        SA = True\n",
    "    if strong >= n/2.:\n",
    "        S2 = True\n",
    "    if SA == True and strong >= 95.*n/100:\n",
    "        S1 = True\n",
    "    return (S1, S2)\n",
    "            \n",
    "def test_weak(rows):\n",
    "    W = False \n",
    "    West = False \n",
    "    SW = False\n",
    "    n = len(rows)\n",
    "    weak = 0\n",
    "    weakest = 0\n",
    "    sweak = 0\n",
    "    for ind, row in rows.iterrows():\n",
    "        if row.ppl>0.1:\n",
    "            weakest += 1\n",
    "            if row.ntail>=50:\n",
    "                weak += 1\n",
    "        if row.dexp >-1 and row.dln>-1  and row.dstrexp >-1  and row.dplwc >-1:\n",
    "            sweak += 1\n",
    "    if weak >= n/2.:\n",
    "        W = True\n",
    "    if weakest >= n/2.:\n",
    "        West = True\n",
    "    if sweak >= n/2.:\n",
    "        SW = True\n",
    "    return (W, West, SW)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test diff hypotheses\n",
    "unique_datasets = np.unique(df.fp_gml)\n",
    "hyps = pd.DataFrame(columns = ['Strongest', \"Strong\", \"Weak\", \"Weakest\", \"Super_Weak\", \"Strong_No_PLwC\", \"Strong_No_PLwC_No_Range\",\"Strongest_No_PLwC\", \"No_PLwC_No_Range_Strongest\", \"Weak_PLwC\", \"Weakest_PLwC\", \"Super_Weak_PLwC\", \"Strong_Any\", \"Strong_Any_noplwc\", \"Strong_Any_nobounds\",\"Weak_Any\", \"Weakest_Any\", \"Super_Weak_Any\", \"Domain\", \"Subdomain\", \"median_alpha\", \"n\", \"median_ntail\"], index=unique_datasets )\n",
    "for i, dataset in enumerate(unique_datasets):\n",
    "    query = \"fp_gml == '%s'\" %dataset\n",
    "    rows = df.query(query)\n",
    "    [S1, S2] = test_strong(rows)\n",
    "    hyps.loc[dataset]['Strongest'] = S1\n",
    "    hyps.loc[dataset]['Strong'] = S2\n",
    "    [weak,weakest,superweak] = test_weak(rows)\n",
    "    hyps.loc[dataset]['Weak'] = weak\n",
    "    hyps.loc[dataset]['Weakest'] = weakest\n",
    "    hyps.loc[dataset]['Super_Weak'] = superweak\n",
    "    [A1, A2] = test_strong_noplwc(rows)\n",
    "    hyps.loc[dataset]['Strong_No_PLwC'] = A1\n",
    "    hyps.loc[dataset]['No_PLwC_No_Range'] = A2\n",
    "    [A1S, A2S] = test_strongest_noplwc(rows)\n",
    "    hyps.loc[dataset]['Strongest_No_PLwC']= A1S\n",
    "    hyps.loc[dataset]['No_PLwC_No_Range_Strongest'] = A2S\n",
    "    [W, West, SW] = test_weak_noplwc(rows)\n",
    "    hyps.loc[dataset]['Weak_PLwC'] = W\n",
    "    hyps.loc[dataset]['Weakest_PLwC'] = West\n",
    "    hyps.loc[dataset]['Super_Weak_PLwC'] = SW\n",
    "    S = test_strong_any(rows)\n",
    "    hyps.loc[dataset]['Strong_Any'] = S\n",
    "    S = test_strong_any_noplwc(rows)\n",
    "    hyps.loc[dataset]['Strong_Any_noplwc'] = S\n",
    "    S = test_strong_any_nobounds(rows)\n",
    "    hyps.loc[dataset]['Strong_Any_nobounds'] = S\n",
    "    [W, West, SW] = test_weak_any(rows)\n",
    "    hyps.loc[dataset]['Weak_Any'] = W\n",
    "    hyps.loc[dataset]['Weakest_Any'] = West\n",
    "    hyps.loc[dataset]['Super_Weak_Any'] = SW\n",
    "    hyps.loc[dataset]['Domain'] = rows.Domain[0]\n",
    "    hyps.loc[dataset]['Subdomain'] = rows.Subdomain[0]\n",
    "    hyps.loc[dataset]['median_alpha'] = np.median(rows.alpha)\n",
    "    hyps.loc[dataset]['n'] = np.max(rows.n)\n",
    "    hyps.loc[dataset]['median_ntail'] = np.median(rows.ntail)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strongest = 0.0377562028047\n",
      "Strong = 0.105717367853\n",
      "Weak = 0.24163969795\n",
      "Weakest = 0.333333333333\n",
      "Super Weak = 0.522114347357\n",
      "No PLwC Strong = 0.114347357066\n",
      "No PLwC No Range = 0.228694714132\n",
      "No PLwC Strongest = 0.0442286947141\n",
      "No PLwC No Range = 0.1380798274\n",
      "Weak No PLwC = 0.24163969795\n",
      "Weakest No PLwC = 0.333333333333\n",
      "Super-Weak No PLwC = 0.567421790723\n",
      "Strong Any = 0.188781014024\n",
      "Strong Any No PLWC = 0.196332254585\n",
      "Strong Any No Bounds = 0.314994606257\n",
      "Weak Any = 0.327939590076\n",
      "Weakest Any = 0.425026968716\n",
      "Super-Weak Any = 0.541531823085\n",
      "Number of Datsets = 927\n"
     ]
    }
   ],
   "source": [
    "n = float(len(hyps))\n",
    "Strongest = np.sum(hyps.Strongest)\n",
    "Strong = np.sum(hyps.Strong)\n",
    "Weak = np.sum(hyps.Weak)\n",
    "Weakest = np.sum(hyps.Weakest)\n",
    "Super_Weak = np.sum(hyps.Super_Weak)\n",
    "Strong_No_PLwC = np.sum(hyps.Strong_No_PLwC)\n",
    "Strong_No_PLwC_No_Range = np.sum(hyps.Strong_No_PLwC_No_Range)\n",
    "No_PLwC_Strongest = np.sum(hyps.Strongest_No_PLwC)\n",
    "No_PLwC_No_Range_Strongest = np.sum(hyps.No_PLwC_No_Range_Strongest)\n",
    "Weak_NoPLwC = np.sum(hyps.Weak_PLwC)\n",
    "Weakest_NoPLwC = np.sum(hyps.Weakest_PLwC)\n",
    "Super_Weak_NoPLwC = np.sum(hyps.Super_Weak_PLwC)\n",
    "Strong_Any = np.sum(hyps.Strong_Any)\n",
    "Strong_Any_noplwc = np.sum(hyps.Strong_Any_noplwc)\n",
    "Strong_Any_nobounds = np.sum(hyps.Strong_Any_nobounds)\n",
    "Weak_Any = np.sum(hyps.Weak_Any)\n",
    "Weakest_Any = np.sum(hyps.Weakest_Any)\n",
    "Super_Weak_Any = np.sum(hyps.Super_Weak_Any)\n",
    "print \"Strongest = %s\" %(Strongest/n)\n",
    "print \"Strong = %s\" %(Strong/n)\n",
    "print \"Weak = %s\" %(Weak/n)\n",
    "print \"Weakest = %s\" %(Weakest/n)\n",
    "print \"Super Weak = %s\" %(Super_Weak/n)\n",
    "print \"No PLwC Strong = %s\" %(Strong_No_PLwC/n)\n",
    "print \"No PLwC No Range = %s\" %(No_PLwC_No_Range/n)\n",
    "print \"No PLwC Strongest = %s\" %(No_PLwC_Strongest/n)\n",
    "print \"No PLwC No Range = %s\" %(No_PLwC_No_Range_Strongest/n)\n",
    "print \"Weak No PLwC = %s\" %(Weak_NoPLwC/n)\n",
    "print \"Weakest No PLwC = %s\" %(Weakest_NoPLwC/n)\n",
    "print \"Super-Weak No PLwC = %s\" %(Super_Weak_NoPLwC/n)\n",
    "print \"Strong Any = %s\" %(Strong_Any/n)\n",
    "print \"Strong Any No PLWC = %s\" %(Strong_Any_noplwc/n)\n",
    "print \"Strong Any No Bounds = %s\" %(Strong_Any_nobounds/n)\n",
    "print \"Weak Any = %s\" %(Weak_Any/n)\n",
    "print \"Weakest Any = %s\" %(Weakest_Any/n)\n",
    "print \"Super-Weak Any = %s\" %(Super_Weak_Any/n)\n",
    "print \"Number of Datsets = %s\" %int(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=unique_datasets[0]\n",
    "query = \"fp_gml == '%s'\" %dataset\n",
    "rows = df.query(query)\n",
    "rows\n",
    "A1 = False # noplwcstrongest\n",
    "A2 = False # no plwc or range strongest\n",
    "n = len(rows)\n",
    "nps = 0 #strongestnoplwc\n",
    "npnrs = 0 #noplwcnorange\n",
    "alts = 0\n",
    "for ind, row in rows.iterrows():\n",
    "    if row.ppl>0.1 and row.ntail >= 50:\n",
    "        npnrs += 1\n",
    "        if row.dexp >-1 and row.dln>-1  and row.dstrexp >-1:\n",
    "            alts+= 1\n",
    "        if row.alpha < 3 and row.alpha > 2:\n",
    "            nps += 1\n",
    "if alts >= 95.*n/10. and nps >= 90.*n/100.:\n",
    "    A1 = True\n",
    "if alts >= 95.*n/10. and npnrs >= 95.*n/100.:\n",
    "    A2 = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dsfp = '/Users/annabroido/Dropbox/Research/LRTAnalysis/degreesequences/' # degree sequences\n",
    "\n",
    "# hyps['median_meandeg'] = ''\n",
    "\n",
    "# unique_datasets = np.unique(df.fp_gml)\n",
    "# for i, dataset in enumerate(unique_datasets):\n",
    "#     query = \"fp_gml == '%s'\" %dataset\n",
    "#     rows = df.query(query)\n",
    "#     means = np.zeros(len(rows))\n",
    "#     for r, row in enumerate(rows.iterrows()):\n",
    "#         name = row[1].name\n",
    "#         fp = dsfp + name\n",
    "#         x = im.readdata(fp)\n",
    "#         means[r] = np.mean(x)\n",
    "#     hyps.loc[dataset]['median_meandeg'] = np.median(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyps.to_pickle('/Users/annabroido/Dropbox/Research/LRTAnalysis/SFAnalysis/analysis/newhyps.p')\n",
    "# hyps.to_csv('/Users/annabroido/Dropbox/Research/LRTAnalysis/SFAnalysis/analysis/newhyps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Subdomain</th>\n",
       "      <th>num_edges</th>\n",
       "      <th>Graph_order</th>\n",
       "      <th>Weighted</th>\n",
       "      <th>Directed</th>\n",
       "      <th>Bipartite</th>\n",
       "      <th>Multigraph</th>\n",
       "      <th>Multiplex</th>\n",
       "      <th>Component</th>\n",
       "      <th>...</th>\n",
       "      <th>n</th>\n",
       "      <th>alpha</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ntail</th>\n",
       "      <th>Lpl</th>\n",
       "      <th>ppl</th>\n",
       "      <th>dexp</th>\n",
       "      <th>dln</th>\n",
       "      <th>dstrexp</th>\n",
       "      <th>dplwc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United_States_Road_Networks_PA_Transportation_Roads_n6.gml_multiplexroad_category_multigraphsimplifieddistribution.txt</th>\n",
       "      <td>Transportation</td>\n",
       "      <td>Roads</td>\n",
       "      <td>1078246</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>simplified</td>\n",
       "      <td>sub_road_category</td>\n",
       "      <td>entire</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>6.3</td>\n",
       "      <td>3</td>\n",
       "      <td>456034</td>\n",
       "      <td>-291964</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United_States_Road_Networks_PA_Transportation_Roads_n6.gml_multiplexroad_category_multigraphsimplified_largestcompdistribution.txt</th>\n",
       "      <td>Transportation</td>\n",
       "      <td>Roads</td>\n",
       "      <td>1072638</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>simplified</td>\n",
       "      <td>sub_road_category</td>\n",
       "      <td>largest</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>6.3</td>\n",
       "      <td>3</td>\n",
       "      <td>455270</td>\n",
       "      <td>-291717</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United_States_Road_Networks_PA_Transportation_Roads_n6.gml_multiplextravel_time_multigraphsimplifieddistribution.txt</th>\n",
       "      <td>Transportation</td>\n",
       "      <td>Roads</td>\n",
       "      <td>1078246</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>simplified</td>\n",
       "      <td>sub_travel_time</td>\n",
       "      <td>entire</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>6.3</td>\n",
       "      <td>3</td>\n",
       "      <td>456034</td>\n",
       "      <td>-291964</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United_States_Road_Networks_PA_Transportation_Roads_n6.gml_multiplextravel_time_multigraphsimplified_largestcompdistribution.txt</th>\n",
       "      <td>Transportation</td>\n",
       "      <td>Roads</td>\n",
       "      <td>1072638</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>simplified</td>\n",
       "      <td>sub_travel_time</td>\n",
       "      <td>largest</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>6.3</td>\n",
       "      <td>3</td>\n",
       "      <td>455270</td>\n",
       "      <td>-291717</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United_States_Road_Networks_PA_Transportation_Roads_n6.gml_multiplexspatial_distance_in_meters_multigraphsimplifieddistribution.txt</th>\n",
       "      <td>Transportation</td>\n",
       "      <td>Roads</td>\n",
       "      <td>1078246</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>simplified</td>\n",
       "      <td>sub_spatial_distance_in_meters</td>\n",
       "      <td>entire</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>6.3</td>\n",
       "      <td>3</td>\n",
       "      <td>456034</td>\n",
       "      <td>-291964</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United_States_Road_Networks_PA_Transportation_Roads_n6.gml_multiplexspatial_distance_in_meters_multigraphsimplified_largestcompdistribution.txt</th>\n",
       "      <td>Transportation</td>\n",
       "      <td>Roads</td>\n",
       "      <td>1072638</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>simplified</td>\n",
       "      <td>sub_spatial_distance_in_meters</td>\n",
       "      <td>largest</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>6.3</td>\n",
       "      <td>3</td>\n",
       "      <td>455270</td>\n",
       "      <td>-291717</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            Domain Subdomain  \\\n",
       "United_States_Road_Networks_PA_Transportation_R...  Transportation     Roads   \n",
       "United_States_Road_Networks_PA_Transportation_R...  Transportation     Roads   \n",
       "United_States_Road_Networks_PA_Transportation_R...  Transportation     Roads   \n",
       "United_States_Road_Networks_PA_Transportation_R...  Transportation     Roads   \n",
       "United_States_Road_Networks_PA_Transportation_R...  Transportation     Roads   \n",
       "United_States_Road_Networks_PA_Transportation_R...  Transportation     Roads   \n",
       "\n",
       "                                                   num_edges Graph_order  \\\n",
       "United_States_Road_Networks_PA_Transportation_R...   1078246           6   \n",
       "United_States_Road_Networks_PA_Transportation_R...   1072638           6   \n",
       "United_States_Road_Networks_PA_Transportation_R...   1078246           6   \n",
       "United_States_Road_Networks_PA_Transportation_R...   1072638           6   \n",
       "United_States_Road_Networks_PA_Transportation_R...   1078246           6   \n",
       "United_States_Road_Networks_PA_Transportation_R...   1072638           6   \n",
       "\n",
       "                                                   Weighted Directed  \\\n",
       "United_States_Road_Networks_PA_Transportation_R...        0        0   \n",
       "United_States_Road_Networks_PA_Transportation_R...        0        0   \n",
       "United_States_Road_Networks_PA_Transportation_R...        0        0   \n",
       "United_States_Road_Networks_PA_Transportation_R...        0        0   \n",
       "United_States_Road_Networks_PA_Transportation_R...        0        0   \n",
       "United_States_Road_Networks_PA_Transportation_R...        0        0   \n",
       "\n",
       "                                                   Bipartite  Multigraph  \\\n",
       "United_States_Road_Networks_PA_Transportation_R...         0  simplified   \n",
       "United_States_Road_Networks_PA_Transportation_R...         0  simplified   \n",
       "United_States_Road_Networks_PA_Transportation_R...         0  simplified   \n",
       "United_States_Road_Networks_PA_Transportation_R...         0  simplified   \n",
       "United_States_Road_Networks_PA_Transportation_R...         0  simplified   \n",
       "United_States_Road_Networks_PA_Transportation_R...         0  simplified   \n",
       "\n",
       "                                                                         Multiplex  \\\n",
       "United_States_Road_Networks_PA_Transportation_R...               sub_road_category   \n",
       "United_States_Road_Networks_PA_Transportation_R...               sub_road_category   \n",
       "United_States_Road_Networks_PA_Transportation_R...                 sub_travel_time   \n",
       "United_States_Road_Networks_PA_Transportation_R...                 sub_travel_time   \n",
       "United_States_Road_Networks_PA_Transportation_R...  sub_spatial_distance_in_meters   \n",
       "United_States_Road_Networks_PA_Transportation_R...  sub_spatial_distance_in_meters   \n",
       "\n",
       "                                                   Component  ...  n alpha  \\\n",
       "United_States_Road_Networks_PA_Transportation_R...    entire  ...      6.3   \n",
       "United_States_Road_Networks_PA_Transportation_R...   largest  ...      6.3   \n",
       "United_States_Road_Networks_PA_Transportation_R...    entire  ...      6.3   \n",
       "United_States_Road_Networks_PA_Transportation_R...   largest  ...      6.3   \n",
       "United_States_Road_Networks_PA_Transportation_R...    entire  ...      6.3   \n",
       "United_States_Road_Networks_PA_Transportation_R...   largest  ...      6.3   \n",
       "\n",
       "                                                   xmin   ntail     Lpl ppl  \\\n",
       "United_States_Road_Networks_PA_Transportation_R...    3  456034 -291964   0   \n",
       "United_States_Road_Networks_PA_Transportation_R...    3  455270 -291717   0   \n",
       "United_States_Road_Networks_PA_Transportation_R...    3  456034 -291964   0   \n",
       "United_States_Road_Networks_PA_Transportation_R...    3  455270 -291717   0   \n",
       "United_States_Road_Networks_PA_Transportation_R...    3  456034 -291964   0   \n",
       "United_States_Road_Networks_PA_Transportation_R...    3  455270 -291717   0   \n",
       "\n",
       "                                                   dexp dln dstrexp dplwc  \n",
       "United_States_Road_Networks_PA_Transportation_R...   -1  -1      -1    -1  \n",
       "United_States_Road_Networks_PA_Transportation_R...   -1  -1      -1    -1  \n",
       "United_States_Road_Networks_PA_Transportation_R...   -1  -1      -1    -1  \n",
       "United_States_Road_Networks_PA_Transportation_R...   -1  -1      -1    -1  \n",
       "United_States_Road_Networks_PA_Transportation_R...   -1  -1      -1    -1  \n",
       "United_States_Road_Networks_PA_Transportation_R...   -1  -1      -1    -1  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strongest = 0.0\n",
      "Strong = 0.0\n",
      "Weak = 0.551724137931\n",
      "Weakest = 0.696551724138\n",
      "Super Weak = 0.710344827586\n",
      "No PLwC = 0.0\n",
      "No PLwC No Range = 0.48275862069\n",
      "No PLwC Strongest = 0.0\n",
      "No PLwC No Range = 0.406896551724\n",
      "Strong Any = 0.0137931034483\n",
      "Strong Any No PLWC = 0.0137931034483\n",
      "Strong Any No Bounds = 0.503448275862\n",
      "Weak Any = 0.572413793103\n",
      "Weakest Any = 0.710344827586\n",
      "Super-Weak Any = 0.71724137931\n",
      "Number of Datsets = 145\n"
     ]
    }
   ],
   "source": [
    "subhyps = hyps.query(\"Domain=='Social'\")\n",
    "n = float(len(subhyps))\n",
    "Strongest = np.sum(subhyps.Strongest)\n",
    "Strong = np.sum(subhyps.Strong)\n",
    "Weak = np.sum(subhyps.Weak)\n",
    "Weakest = np.sum(subhyps.Weakest)\n",
    "Super_Weak = np.sum(subhyps.Super_Weak)\n",
    "No_PLwC = np.sum(subhyps.No_PLwC)\n",
    "No_PLwC_No_Range = np.sum(subhyps.No_PLwC_No_Range)\n",
    "No_PLwC_Strongest = np.sum(subhyps.No_PLwC_Strongest)\n",
    "No_PLwC_No_Range_Strongest = np.sum(subhyps.No_PLwC_No_Range_Strongest)\n",
    "Strong_Any = np.sum(subhyps.Strong_Any)\n",
    "Strong_Any_noplwc = np.sum(subhyps.Strong_Any_noplwc)\n",
    "Strong_Any_nobounds = np.sum(subhyps.Strong_Any_nobounds)\n",
    "Weak_Any = np.sum(subhyps.Weak_Any)\n",
    "Weakest_Any = np.sum(subhyps.Weakest_Any)\n",
    "Super_Weak_Any = np.sum(subhyps.Super_Weak_Any)\n",
    "print \"Strongest = %s\" %(Strongest/n)\n",
    "print \"Strong = %s\" %(Strong/n)\n",
    "print \"Weak = %s\" %(Weak/n)\n",
    "print \"Weakest = %s\" %(Weakest/n)\n",
    "print \"Super Weak = %s\" %(Super_Weak/n)\n",
    "print \"No PLwC = %s\" %(No_PLwC/n)\n",
    "print \"No PLwC No Range = %s\" %(No_PLwC_No_Range/n)\n",
    "print \"No PLwC Strongest = %s\" %(No_PLwC_Strongest/n)\n",
    "print \"No PLwC No Range = %s\" %(No_PLwC_No_Range_Strongest/n)\n",
    "print \"Strong Any = %s\" %(Strong_Any/n)\n",
    "print \"Strong Any No PLWC = %s\" %(Strong_Any_noplwc/n)\n",
    "print \"Strong Any No Bounds = %s\" %(Strong_Any_nobounds/n)\n",
    "print \"Weak Any = %s\" %(Weak_Any/n)\n",
    "print \"Weakest Any = %s\" %(Weakest_Any/n)\n",
    "print \"Super-Weak Any = %s\" %(Super_Weak_Any/n)\n",
    "print \"Number of Datsets = %s\" %int(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
