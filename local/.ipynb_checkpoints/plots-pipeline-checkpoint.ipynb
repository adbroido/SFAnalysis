{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_pickle('/Users/annabroido/Dropbox/Research/LRTAnalysis/LRTAnalysis/analysis/analysis.p')\n",
    "# NOTE THAT 'IN' MEAN IN TO THE ALT DISTRIBUTION, WHCIH IS NOT WHAT MATHEMATICA DOES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getcount(decision, direction):\n",
    "    directiondir = {'in':'-1', 'out':'1', 'unk':'0', 'fail':'2'}\n",
    "    query = '%s == %s' %(decision, directiondir[direction])\n",
    "    num = len(np.asarray(df.query(query)[decision], dtype=int))\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[415, 317, 388, 489]\n",
      "[136, 1069, 852, 0]\n",
      "[1239, 301, 500, 1333]\n"
     ]
    }
   ],
   "source": [
    "# plot some stuff\n",
    "expin = getcount('dexp', 'in')\n",
    "expout = getcount('dexp', 'out')\n",
    "expunk = getcount('dexp', 'unk')\n",
    "lnin = getcount('dln', 'in')\n",
    "lnout = getcount('dln', 'out')\n",
    "lnunk = getcount('dln', 'unk')\n",
    "strexpin = getcount('dstrexp', 'in')\n",
    "strexpout = getcount('dstrexp', 'out')\n",
    "strexpunk = getcount('dstrexp', 'unk')\n",
    "plwcin = getcount('dplwc', 'in')\n",
    "plwcout = getcount('dplwc', 'out')\n",
    "plwcunk = getcount('dplwc', 'unk')\n",
    "# order = \"LN\", \"Exp\", \"Str Exp\", \"PLwC\"\n",
    "incounts = [lnin, expin, strexpin, plwcin]\n",
    "outcounts = [lnout, expout, strexpout, plwcout]\n",
    "unkcounts = [lnunk, expunk, strexpunk, plwcunk]\n",
    "print incounts\n",
    "print outcounts\n",
    "print unkcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doms = np.unique(df.Domain)\n",
    "# number of graphs and mean alpha value in each domain\n",
    "counts = np.zeros_like(doms)\n",
    "means = np.zeros_like(doms)\n",
    "counts_plaus = np.zeros_like(doms)\n",
    "means_plaus = np.zeros_like(doms)\n",
    "counts_plaustail = np.zeros_like(doms)\n",
    "means_plaustail = np.zeros_like(doms)\n",
    "for i,dom in enumerate(doms):\n",
    "    query = \"Domain == '%s'\" %dom\n",
    "    subdf = df.query(query)\n",
    "    counts[i] = len(subdf)\n",
    "    means[i] = format(np.mean(subdf.alpha), '.2f')\n",
    "    subdf_plaus = subdf.query(\"ppl>0.1\")\n",
    "    counts_plaus[i] = len(subdf_plaus)\n",
    "    means_plaus[i] = format(np.mean(subdf_plaus.alpha), '.2f')\n",
    "    subdf_plaustail = subdf_plaus.query(\"ntail>=50\")\n",
    "    counts_plaustail[i] = len(subdf_plaustail)\n",
    "    means_plaustail[i] = format(np.mean(subdf_plaustail.alpha), '.2f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Biological' 'Economic' 'Informational' 'Social' 'Technological'\n",
      " 'Transportation']\n",
      "[53 0 6 106 799 1]\n",
      "['2.69' 'nan' '2.38' '4.74' '2.23' '4.82']\n"
     ]
    }
   ],
   "source": [
    "print doms\n",
    "print counts_plaustail\n",
    "print means_plaustail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataframe\n",
    "df = pd.read_pickle('/Users/annabroido/Dropbox/Research/LRTAnalysis/LRTAnalysis/analysis/gmlcatalog.p')\n",
    "len(df.query('Domain == \"Informational\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_strong(rows):\n",
    "    SA = False # strong alone\n",
    "    S1 = False # strong 1\n",
    "    S2 = False # strong 2\n",
    "    n = len(rows)\n",
    "    strong = 0\n",
    "    strong_alone = 0\n",
    "    for ind, row in rows.iterrows():\n",
    "        if row.ppl>0.1 and row.ntail >= 50 and row.alpha < 3 and row.alpha > 2:\n",
    "            strong_alone += 1\n",
    "            if row.dexp >-1 and row.dln>-1  and row.dstrexp >-1  and row.dplwc >-1:\n",
    "                strong += 1\n",
    "    if strong_alone >= n/2:\n",
    "        SA = True\n",
    "    if strong >= n/2:\n",
    "        S2 = True\n",
    "    if strong >= 9*n/10:\n",
    "        S1 = True\n",
    "    return (S1, S2, SA)\n",
    "            \n",
    "def test_weak(rows):\n",
    "    W = False \n",
    "    West = False \n",
    "    n = len(rows)\n",
    "    weak = 0\n",
    "    weakest = 0\n",
    "    for ind, row in rows.iterrows():\n",
    "        if row.ppl>0.1:\n",
    "            weakest += 1\n",
    "            if row.ntail>=50:\n",
    "                weak += 1\n",
    "    if weak >= n/2:\n",
    "        W = True\n",
    "    if weakest >= n/2:\n",
    "        West = True\n",
    "    return (W, West)\n",
    "            \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test diff hypotheses\n",
    "unique_datasets = np.unique(df.fp_gml)\n",
    "counts = pd.DataFrame(columns = ['Strong1', \"Strong2\", \"Strong_alone\", \"Weak\", \"Weakest\"], index=unique_datasets )\n",
    "for i, dataset in enumerate(unique_datasets):\n",
    "    query = \"fp_gml == '%s'\" %dataset\n",
    "    rows = df.query(query)\n",
    "    [S1, S2, SA] = test_strong(rows)\n",
    "    counts.loc[dataset]['Strong1'] = S1\n",
    "    counts.loc[dataset]['Strong2'] = S2\n",
    "    counts.loc[dataset]['Strong_alone'] = SA\n",
    "    [weak,weakest] = test_weak(rows)\n",
    "    counts.loc[dataset]['Weak'] = weak\n",
    "    counts.loc[dataset]['Weakest'] = weakest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = unique_datasets[0]\n",
    "query = \"fp_gml == '%s'\" %dataset\n",
    "rows = df.query(query)\n",
    "[S1, S2, SA] = test_strong(rows)\n",
    "counts.loc[dataset]['Strong1'] = S1\n",
    "counts.loc[dataset]['Strong2'] = S2\n",
    "counts.loc[dataset]['Strong_alone'] = SA\n",
    "[weak,weakest] = test_weak(rows)\n",
    "counts.loc[dataset]['Weak'] = weak\n",
    "counts.loc[dataset]['Weakest'] = weakest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong1 = 962\n",
      "Strong2 = 1096\n",
      "Strong_alone = 1108\n",
      "Weak = 1190\n",
      "Weakest = 1353\n",
      "Number of Datsets = 1823\n"
     ]
    }
   ],
   "source": [
    "n = len(df)\n",
    "Strong1 = np.sum(counts.Strong1)\n",
    "Strong2 = np.sum(counts.Strong2)\n",
    "Strong_alone = np.sum(counts.Strong_alone)\n",
    "Weak = np.sum(counts.Weak)\n",
    "Weakest = np.sum(counts.Weakest)\n",
    "print \"Strong1 = %s\" %Strong1\n",
    "print \"Strong2 = %s\" %Strong2\n",
    "print \"Strong_alone = %s\" %Strong_alone\n",
    "print \"Weak = %s\" %Weak\n",
    "print \"Weakest = %s\" %Weakest\n",
    "print \"Number of Datsets = %s\" %len(unique_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Subdomain</th>\n",
       "      <th>num_edges</th>\n",
       "      <th>Graph_order</th>\n",
       "      <th>Weighted</th>\n",
       "      <th>Directed</th>\n",
       "      <th>Bipartite</th>\n",
       "      <th>Multigraph</th>\n",
       "      <th>Multiplex</th>\n",
       "      <th>Component</th>\n",
       "      <th>...</th>\n",
       "      <th>n</th>\n",
       "      <th>alpha</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ntail</th>\n",
       "      <th>Lpl</th>\n",
       "      <th>ppl</th>\n",
       "      <th>dexp</th>\n",
       "      <th>dln</th>\n",
       "      <th>dstrexp</th>\n",
       "      <th>dplwc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mouse_suprachiasmatic_nucleus_scn3_Biological_Connectome_n3.gml_multigraphsimplifieddistribution.txt</th>\n",
       "      <td>Biological</td>\n",
       "      <td>Connectome</td>\n",
       "      <td>724</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>simplified</td>\n",
       "      <td>0</td>\n",
       "      <td>entire</td>\n",
       "      <td>...</td>\n",
       "      <td>430</td>\n",
       "      <td>6.5</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>-39.5079</td>\n",
       "      <td>0.914</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Domain   Subdomain  \\\n",
       "Mouse_suprachiasmatic_nucleus_scn3_Biological_C...  Biological  Connectome   \n",
       "\n",
       "                                                   num_edges Graph_order  \\\n",
       "Mouse_suprachiasmatic_nucleus_scn3_Biological_C...       724           3   \n",
       "\n",
       "                                                   Weighted Directed  \\\n",
       "Mouse_suprachiasmatic_nucleus_scn3_Biological_C...        0        0   \n",
       "\n",
       "                                                   Bipartite  Multigraph  \\\n",
       "Mouse_suprachiasmatic_nucleus_scn3_Biological_C...         0  simplified   \n",
       "\n",
       "                                                   Multiplex Component  ...   \\\n",
       "Mouse_suprachiasmatic_nucleus_scn3_Biological_C...         0    entire  ...    \n",
       "\n",
       "                                                      n alpha xmin ntail  \\\n",
       "Mouse_suprachiasmatic_nucleus_scn3_Biological_C...  430   6.5   20    17   \n",
       "\n",
       "                                                        Lpl    ppl dexp dln  \\\n",
       "Mouse_suprachiasmatic_nucleus_scn3_Biological_C... -39.5079  0.914   -1  -1   \n",
       "\n",
       "                                                   dstrexp dplwc  \n",
       "Mouse_suprachiasmatic_nucleus_scn3_Biological_C...      -1     0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"fp_gml == '%s'\" %'/Volumes/Durodon/gmls/Biological/Connectome/n3/Mouse_suprachiasmatic_nucleus_scn3_Biological_Connectome_n3.gml'\n",
    "df.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
